import ollama
import pytesseract
from PIL import Image
import sys
import os
import time
import io

# --- CONFIGURA√á√ïES ---
ARQUIVO_IMAGEM = "teste2.png" 
# Certifique-se de usar o nome exato do modelo que funcionou para voc√™
MODELO_VISAO = "qwen2.5vl:3b" 

def converter_para_bytes(imagem_pil):
    """Converte uma imagem PIL para bytes prontos para o Ollama."""
    img_byte_arr = io.BytesIO()
    imagem_pil.save(img_byte_arr, format='PNG')
    return img_byte_arr.getvalue()

def teste_otimizado():
    if not os.path.exists(ARQUIVO_IMAGEM):
        print(f"‚ùå Erro: Arquivo '{ARQUIVO_IMAGEM}' n√£o encontrado.")
        return

    print(f"üîß Carregando imagem: {ARQUIVO_IMAGEM}")
    
    # 1. Carregar Imagem ORIGINAL (Alta Resolu√ß√£o)
    try:
        img_original = Image.open(ARQUIVO_IMAGEM)
        print(f"   ‚Ü≥ Resolu√ß√£o original: {img_original.size}")
    except Exception as e:
        print(f"‚ùå Erro ao abrir imagem: {e}")
        return

    # 2. OCR na ORIGINAL (Aqui est√° o segredo da qualidade)
    #    Rodamos o Tesseract antes de reduzir, garantindo que ele leia as letras mi√∫das.
    print("   ‚Ü≥ üìñ Executando OCR na imagem original (Alta Fidelidade)...")
    start_ocr = time.time()
    custom_config = r'--oem 3 --psm 3'
    texto_ocr = pytesseract.image_to_string(img_original, lang='por+eng', config=custom_config)
    print(f"      ‚úÖ OCR conclu√≠do em {time.time() - start_ocr:.2f}s. Caracteres extra√≠dos: {len(texto_ocr)}")

    # 3. Redimensionar C√≥pia para a IA (Para caber na GPU)
    #    Criamos uma c√≥pia para n√£o afetar a original caso precisasse usar de novo
    img_gpu = img_original.copy()
    MAX_SIZE = 768 # Tamanho seguro para VRAM e Contexto
    img_gpu.thumbnail((MAX_SIZE, MAX_SIZE))
    print(f"   ‚Ü≥ üìâ C√≥pia redimensionada para {img_gpu.size} para envio √† GPU.")
    
    # Prepara os bytes da imagem reduzida
    img_bytes_envio = converter_para_bytes(img_gpu)

    # 4. Enviar para IA com contexto controlado
    print("\nüöÄ Enviando para o Ollama (GPU)...")
    start_ai = time.time()
    
    prompt = (
        f"Analise esta imagem retirada de um documento acad√™mico.\n"
        f"Abaixo est√° o texto extra√≠do via OCR da imagem original para te ajudar a ler detalhes pequenos:\n"
        f"'''{texto_ocr}'''\n\n"
        f"Com base na imagem visual (estrutura/formas) e no texto de apoio acima, explique detalhadamente o que √© mostrado e qual a conclus√£o principal."
    )

    try:
        response = ollama.chat(
            model=MODELO_VISAO,
            messages=[{
                'role': 'user',
                'content': prompt,
                'images': [img_bytes_envio] # Envia APENAS a vers√£o leve
            }],
            options={
                'num_ctx': 2048,   # Contexto reduzido para garantir que cabe na VRAM
                'temperature': 0.1 # Temperatura baixa para ser fiel aos dados
            }
        )
        print("\nü§ñ RESPOSTA:")
        print("-" * 50)
        print(response['message']['content'])
        print("-" * 50)
        print(f"‚è±Ô∏è Tempo total da IA: {time.time() - start_ai:.2f}s")
        
    except Exception as e:
        print(f"\n‚ùå Erro na comunica√ß√£o com Ollama: {e}")
        # Dica de debug caso falhe
        if "truncating" in str(e):
            print("üí° Dica: O contexto estourou. Tente diminuir ainda mais a imagem ou aumentar num_ctx levemente.")

if __name__ == "__main__":
    teste_otimizado()